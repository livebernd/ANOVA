{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57804ffe",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "876b85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec5100",
   "metadata": {},
   "source": [
    "# Article Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8bf4ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               label  nb_visits  nb_hits  \\\n",
      "0  Valg av benledningsimplantat ved ensidig døvhe...         54      119   \n",
      "1                   Hearing Loss and Health Problems         52      109   \n",
      "2  The Oldest CI Recipient Celebrates Her 100th B...         42       91   \n",
      "3                          Hearing and Mental Health         38       80   \n",
      "4                  Types and Degrees of Hearing Loss         16       31   \n",
      "5              How much does a hearing implant cost?         14       30   \n",
      "6                          Tipi e gradi di ipoacusia         12       26   \n",
      "7  Pioneers, Passion and Perserverance - the Hist...          7       14   \n",
      "8                  Quanto costa un impianto uditivo?          7        8   \n",
      "9  Che differenza c’è tra un apparecchio acustico...          6        8   \n",
      "\n",
      "   nb_hits_with_time_generation  min_time_generation  max_time_generation  \\\n",
      "0                           106                    3                    3   \n",
      "1                           104                    5                    5   \n",
      "2                            77                    2                    2   \n",
      "3                            78                    5                    5   \n",
      "4                            29                    5                    5   \n",
      "5                            30                    1                    1   \n",
      "6                            26                    4                    4   \n",
      "7                            14                    2                    2   \n",
      "8                             8                    5                    5   \n",
      "9                             8                    4                    4   \n",
      "\n",
      "   sum_time_network  nb_hits_with_time_network  min_time_network  \\\n",
      "0               217                          3                 0   \n",
      "1                 0                          2                 0   \n",
      "2                 0                          3                 0   \n",
      "3                 0                          1                 0   \n",
      "4                 0                          0                 0   \n",
      "5                 0                          0                 0   \n",
      "6                 0                          0                 0   \n",
      "7                 0                          0                 0   \n",
      "8                 0                          0                 0   \n",
      "9                 0                          0                 0   \n",
      "\n",
      "   max_time_network  ...  max_time_on_load  sum_time_spent  bounce_count  \\\n",
      "0               156  ...                 6            2527             0   \n",
      "1                 0  ...                 1             779             0   \n",
      "2                 0  ...                 2             383             0   \n",
      "3                 0  ...                 0            1238             0   \n",
      "4                 0  ...                 0             575             0   \n",
      "5                 0  ...                 0             111             0   \n",
      "6                 0  ...                 0             358             0   \n",
      "7                 0  ...                 0            1054             0   \n",
      "8                 0  ...                 0             135             0   \n",
      "9                 0  ...                 0             321             0   \n",
      "\n",
      "   exit_nb_visits  sum_daily_nb_uniq_visitors  avg_time_on_dimension  \\\n",
      "0              30                          53                     21   \n",
      "1              19                          52                      7   \n",
      "2              25                          42                      4   \n",
      "3              12                          38                     15   \n",
      "4               5                          16                     19   \n",
      "5               5                          13                      4   \n",
      "6               3                          11                     14   \n",
      "7               2                           7                     75   \n",
      "8               1                           7                     17   \n",
      "9               2                           6                     40   \n",
      "\n",
      "   bounce_rate  exit_rate  avg_time_generation  \\\n",
      "0            0       0,56                    1   \n",
      "1            0       0,37                    1   \n",
      "2            0        0,6                    1   \n",
      "3            0       0,32                    1   \n",
      "4            0       0,31                    1   \n",
      "5            0       0,36                    1   \n",
      "6            0       0,25                    1   \n",
      "7            0       0,29                    1   \n",
      "8            0       0,14                    1   \n",
      "9            0       0,33                    1   \n",
      "\n",
      "                                   Metadata: segment  \n",
      "0  dimension3==Valg+av+benledningsimplantat+ved+e...  \n",
      "1       dimension3==Hearing+Loss+and+Health+Problems  \n",
      "2  dimension3==The+Oldest+CI+Recipient+Celebrates...  \n",
      "3              dimension3==Hearing+and+Mental+Health  \n",
      "4      dimension3==Types+and+Degrees+of+Hearing+Loss  \n",
      "5  dimension3==How+much+does+a+hearing+implant+co...  \n",
      "6              dimension3==Tipi+e+gradi+di+ipoacusia  \n",
      "7  dimension3==Pioneers%2C+Passion+and+Perservera...  \n",
      "8    dimension3==Quanto+costa+un+impianto+uditivo%3F  \n",
      "9  dimension3==Che+differenza+c%E2%80%99%C3%A8+tr...  \n",
      "\n",
      "[10 rows x 39 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkaufman\\AppData\\Local\\Temp\\ipykernel_23856\\1780931330.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_article_names= pd.read_csv('U:/Documents/HP_Content_Performance/Article_Names.csv', error_bad_lines=False, sep=';' )\n"
     ]
    }
   ],
   "source": [
    "# Read CSV from directory\n",
    "\n",
    "df_article_names= pd.read_csv('U:/Documents/HP_Content_Performance/Article_Names.csv', error_bad_lines=False, sep=';' )\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_article_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "052c917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nb_hits  nb_visits  sum_time_spent exit_rate\n",
      "0      119         54            2527      0,56\n",
      "1      109         52             779      0,37\n",
      "2       91         42             383       0,6\n",
      "3       80         38            1238      0,32\n",
      "4       31         16             575      0,31\n",
      "5       30         14             111      0,36\n",
      "6       26         12             358      0,25\n",
      "7       14          7            1054      0,29\n",
      "8        8          7             135      0,14\n",
      "9        8          6             321      0,33\n"
     ]
    }
   ],
   "source": [
    "# Droping features from DataFrame \n",
    "df_articles_num = df_article_names[['nb_hits', 'nb_visits', 'sum_time_spent', 'exit_rate']]\n",
    "print(df_articles_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315d1f3",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk Test of Normal Ditsribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afd1f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Test\n",
      "Test Statistic: 0.9906245470046997, P-value: 0.7150147557258606\n",
      "Data follows a normal distribution (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "df_article_num = np.random.normal(loc=0, scale=1, size=100)  # Generating a normally distributed dataset for demonstration\n",
    "\n",
    "# Shapiro-Wilk Test\n",
    "shapiro_test_statistic, shapiro_p_value = stats.shapiro(df_article_num)\n",
    "print(\"Shapiro-Wilk Test\")\n",
    "print(f\"Test Statistic: {shapiro_test_statistic}, P-value: {shapiro_p_value}\")\n",
    "if shapiro_p_value > 0.05:\n",
    "    print(\"Data follows a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Data does not follow a normal distribution (reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35675f",
   "metadata": {},
   "source": [
    "# Check Homogeneity of Variances using Levene's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72f434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test Statistic: 6.911711165981012, P-value: 0.0009747590214503621\n",
      "The test found a significant difference in variances, suggesting that the assumption of homogeneity of variances has been violated.\n"
     ]
    }
   ],
   "source": [
    "# Sample data: Replace these variables with your actual dataset columns or arrays\n",
    "\n",
    "nb_hits = [119, 109, 91, 80, 31,30,26,14,8,8]  # Data for group 1\n",
    "nb_visits = [54, 52, 42, 38, 16, 14, 12, 7,7]  # Data for group 2\n",
    "sum_time_spent = [2527, 779, 383, 1238, 575, 111, 358, 1054,135]  # Data for group 3\n",
    "exit_rate = [0.56,0.37,0.6, 0.32, 0.31, 0.36, 0.25, 0.29, 0.14] # Data for group 3\n",
    "\n",
    "# Perform Levene's test\n",
    "statistic, p_value = stats.levene(nb_hits,nb_visits,sum_time_spent, exit_rate)\n",
    "\n",
    "print(f\"Levene's Test Statistic: {statistic}, P-value: {p_value}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_value < 0.05:\n",
    "    print(\"The test found a significant difference in variances, suggesting that the assumption of homogeneity of variances has been violated.\")\n",
    "else:\n",
    "    print(\"The test found no significant difference in variances, suggesting that the assumption of homogeneity of variances holds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe27c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data: Replace these variables with your actual dataset columns or arrays\n",
    "\n",
    "nb_hits = [119, 109, 91, 80, 31,30,26,14,8,8]  # Data for group 1\n",
    "nb_visits = [54, 52, 42, 38, 16, 14, 12, 7,7]  # Data for group 2\n",
    "sum_time_spent = [2527, 779, 383, 1238, 575, 111, 358, 1054,135]  # Data for group 3\n",
    "exit_rate = [0.56,0.37,0.6, 0.32, 0.31, 0.36, 0.25, 0.29, 0.14] # Data for group 3\n",
    "\n",
    "# Perform Levene's test\n",
    "statistic, p_value = stats.levene(nb_hits,nb_visits,sum_time_spent, exit_rate)\n",
    "\n",
    "print(f\"Levene's Test Statistic: {statistic}, P-value: {p_value}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_value < 0.05:\n",
    "    print(\"The test found a significant difference in variances, suggesting that the assumption of homogeneity of variances has been violated.\")\n",
    "else:\n",
    "    print(\"The test found no significant difference in variances, suggesting that the assumption of homogeneity of variances holds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ad6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1  var2    var3  var4  log_var1  log_var2  log_var3  log_var4\n",
      "0   119  54.0  2527.0  0.56  4.787492  4.007333  7.835184  0.444686\n",
      "1   109  52.0   779.0  0.37  4.700480  3.970292  6.659294  0.314811\n",
      "2    91  42.0   383.0  0.60  4.521789  3.761200  5.950643  0.470004\n",
      "3    80  38.0  1238.0  0.32  4.394449  3.663562  7.122060  0.277632\n",
      "4    31  16.0   575.0  0.31  3.465736  2.833213  6.356108  0.270027\n",
      "5    30  14.0   111.0  0.36  3.433987  2.708050  4.718499  0.307485\n",
      "6    26  12.0   358.0  0.25  3.295837  2.564949  5.883322  0.223144\n",
      "7    14   7.0  1054.0  0.29  2.708050  2.079442  6.961296  0.254642\n",
      "8     8   7.0   135.0  0.14  2.197225  2.079442  4.912655  0.131028\n",
      "9     8   NaN     NaN   NaN  2.197225       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Corrected DataFrame setup using the 'data' dictionary\n",
    "data = {\n",
    "    'var1': [119, 109, 91, 80, 31, 30, 26, 14, 8, 8],\n",
    "    'var2': [54, 52, 42, 38, 16, 14, 12, 7, 7, np.nan],  # Added np.nan to match length\n",
    "    'var3': [2527, 779, 383, 1238, 575, 111, 358, 1054, 135, np.nan],  # Added np.nan to match length\n",
    "    'var4': [0.56, 0.37, 0.6, 0.32, 0.31, 0.36, 0.25, 0.29, 0.14, np.nan],  # Added np.nan to match length\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying log transformation to specific columns\n",
    "df['log_var1'] = np.log(df['var1'] + 1)  # +1 to handle any zero values\n",
    "df['log_var2'] = np.log(df['var2'] + 1)\n",
    "df['log_var3'] = np.log(df['var3'] + 1)  # Assuming you want to apply it to 'var3' as well\n",
    "df['log_var4'] = np.log(df['var4'] + 1)  # Applying to 'var4'\n",
    "\n",
    "# Display the DataFrame to verify changes\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2ca4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test for log_var1 - Statistic: 2.442490426581486e+29, P-value: 2.0737714991511295e-73\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample group variable - replace this with your actual grouping variable\n",
    "df['label'] = ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E', 'E']  # Example grouping variable\n",
    "\n",
    "# Levene's Test for 'log_var1' across the groups defined by 'group'\n",
    "statistic, p_value = stats.levene(df['log_var1'][df['group'] == 'A'],\n",
    "                                  df['log_var1'][df['group'] == 'B'],\n",
    "                                  df['log_var1'][df['group'] == 'C'],\n",
    "                                  df['log_var1'][df['group'] == 'D'],\n",
    "                                  df['log_var1'][df['group'] == 'E'])\n",
    "\n",
    "print(f\"Levene's Test for log_var1 - Statistic: {statistic}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b20e9f",
   "metadata": {},
   "source": [
    "# Perform ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8a4f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           df    sum_sq   mean_sq          F    PR(>F)\n",
      "group     4.0  8.777264  2.194316  59.259797  0.000212\n",
      "Residual  5.0  0.185144  0.037029        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example setup: Ensure your DataFrame (df) is correctly set up with 'group' as the categorical variable\n",
    "# and 'log_var1' as one of the dependent variables.\n",
    "\n",
    "# Perform one-way ANOVA on log_var1\n",
    "model = ols('log_var1 ~ group', data=df).fit()\n",
    "anova_results = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28bcab",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "Given the results, you can reject the null hypothesis that there is no difference among the group means for log_var1. There is significant evidence to suggest that at least one group mean is different from the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37baf304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
